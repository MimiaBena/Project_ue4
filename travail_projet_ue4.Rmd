---
title: "Entropot et fouille de donnÃ©es"
author: "Benaouali MOkhtaria & belkacem Noor elhouda"
date: "9 janvier 2019"
output:
  html_document: default
  pdf_document: default
---
## 1-Introduction :
La fouille de données (data mining) désigne l’analyse de données depuis différentes perspectives et le fait de transformer ces données en informations utiles, alors c’est une discipline qui permet de faire un lien entre les statistiques et  les technologies de l’information (base de données, intelligence artificielle, apprentissage automatique (machine learning). Au début, la fouille de données était utilisée dans la gestion de la relation client, pour mieux les fidéliser et leur proposer des produits qui leur sont adaptés. Aujourd’hui, la recherche d’informations dans les grandes bases de données médicales ou de santé se développe de plus en plus . Les outils de collecte automatique des données et bases de données permettent de stocker dans des entrepôts d’énormes masses de données. La fouille de données et les entrepôts permettent l’extraction de connaissances.

# 2- Matériels et méthodes 
# Outils utilisées
 -R et Rstudio:
	R est un logiciel permettant de faire des analyses statistiques et permet la production de graphiques évolués. C’est aussi un langage de programmation,. Fonctionnant en console, son utilisation n’est pas aisée. L’interface Rstudio permet une utilisation de R les fonctionnalités de R plus facilement. 
 - Resources cartographiques
Pour pouvoir créer une cartographie sur R, il nous a fallu importer des fonds de cartes. 
1.2- Analyse descriptive des données
	Pour la réalisation du projet, on a utilisé les données de la base Geofla:base de donné qui représente les déchets par établissement  et répartition du radon sur les différentes departements.
Les 2 bases représentent les informations concernant la localisation géographique de chaque établissement (longitude,latitude ,code insee...)
	
#Construisez un mini-entrepôt de données environnementales au format i2b2:
i2b2 (Informatique pour l'intégration de la biologie et du chevet) était un centre national pour l'informatique biomédicale financé par les NIH et basé à Partners HealthCare System. I2b2 NCBC a développé un cadre informatique évolutif conçu pour relier les données de recherche clinique et les vastes banques de données issues de la recherche scientifique fondamentale afin de mieux comprendre les bases génétiques de maladies complexes.
Un entrepôt de données  signifie différentes choses , mais dans notre cas ,l’ entrepôt de données  est le référentiel qui intègre les informations sur les établissements localisés sous les différents départements de la france provenant de sources multiples. Ces informations sont agrégées, nettoyées . Une fois ce processus terminé, on les a présenté  pour interroger .
La principale source de données de notre entrepôt de données  est la base Geofla et le site data,gouv.fr .Nous avons chargé une grande partie des informations  stockées dans cette base, notamment les données géographiques pour chaque département et le taux de déchets de chaque établissement .Dans notre cas on a utilisé la base des déchets radioactifs, la base de potentiel radon dans chaque commune .
On a utilisé un modèle de données simple  Il se compose de faits et de dimensions. Un fait est l’information demandée, et les dimensions sont des groupes de hiérarchies et des descripteurs décrivant les faits. La base de données i2b2 utilise un schéma en étoile qui consiste en une table de faits entourée de nombreuses tables de dimensions (voir la figure ci-dessous). Les faits de i2b2 correspondent à des observations sur les établissements et les paramètres géographique  , notamment l’activité des déchets radioactifs et le potentiel radon
L'un des avantages de l'utilisation de ce type de modèle de données est qu'il est facile d'ajouter et d'intégrer des données provenant de sources multiples sans avoir à redéfinir le système ou à modifier l'architecture sous-jacente. Toutes les nouvelles observations sont simplement ajoutées au tableau des faits.
#Traitement du fichier radon  sous shiny :
Dans cette partie on a exploré notre entrepôt ,en réalisant des cartes interactives sous shiny
1- Répartition du radon en fonction de la localisation des établissements d’émission :
Les données qui ont été élaborées dans la partie (A) sont désormais disponibles dans le dossier projet_ue4 et dans son sous-dossiers carto
Avant toute mise en oeuvre de procédures, il convient de discuter le choix du ou des indicateurs caractéristiques du phénomène que l’on souhaite étudier. Dans l’exemple retenu, le phénomène qui nous intéresse est  la répartition du radon en fonction de la localisation des établissements d’émission . Nous avons choisi de créer ce tableau en ne retenant que de télécharger les tables qui représentent le potentiel radon en fonction des département et la table  des départements et ses données géographiques.



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Tout d’abord,on a importé les packages nécéssaires pour les utilisés par la suite.
```{r }
options(repos = c(CRAN = "http://cran.rstudio.com"))
library(markdown)
library(DCluster)
library(leaflet)
library(shiny)
library(dplyr)
library(sp)
library(rgdal)
library(tidyr)
library(mapproj)
library(maps)
library(dplyr)
```

On a téléchargé les fichiers des données déchetradioactif ,le potentiel radon et la carte géographique des départements de la france.
```{r }

radon <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/radon.csv'
code_postal <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/code-postal-code-insee-2015.csv'
dechets <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/dechets-declares-au-31-12-2015.csv'

dechets <-read.csv(dechets, sep=";")
catalogue_radon <- read.csv(radon, sep=";",encoding='UTF-8')
catalogue_code <- read.csv(code_postal, sep=";",encoding='UTF-8')
```
Téléchargements des données spatiales en utlisant la commande "readOGR"
```{r }
departements<- readOGR("C:/Users/Mimia/Pictures/Documents/projet-ue4/DEPARTEMENT.shp")
 summary(departements)

```
Dans cette étapes, on a renomé les colonnes pour qu'ils soient hétérogènes et on peux les utilisés par la suite.
```{r }
 
colnames(catalogue_code)[colnames(catalogue_code)=="INSEE_COM"] <- "insee_com"
colnames(dechets)[colnames(dechets)=="CODE.INSEE"] <- "insee_com" 

```

On va  fusionner les data frames(catalogue radon qui represente les données du potentiel radon en fonction de chaque département et catalogue code qui représente les données géographioques des départements ) x et y par la colonne name "insse_com" ,on applique la meme commande sur le fichier dechets et catalogue code .


```{r }
radon_code <-merge(catalogue_radon, catalogue_code, by ="insee_com")
dechets_catalog <-merge(dechets, catalogue_code, by ="insee_com") 

```
Dans cette etape, on va créer les 2 coordonnées (longitude et latitude ) à partir de la colonne coordonnees_gps.
```{r }
radon_code<-  radon_code  %>%
  separate(col = "coordonnees_gps",
           into = paste0("coordonnees_gps",1:2), sep = ",",
           extra = "merge")

dechets_catalog <- dechets_catalog  %>%
  separate(col = "coordonnees_gps",
           into = paste0("coordonnees_gps",1:2), sep = ",",
           extra = "merge")
```
la conversion des coordonnéee_gps et la varialbe activité..Bq  en valeur numérique par la commande "as.numeric"
```{r }

dechets_catalog$coordonnees_gps1=as.numeric(as.character(dechets_catalog$coordonnees_gps1))
dechets_catalog$coordonnees_gps2=as.numeric(as.character(dechets_catalog$coordonnees_gps2))
dechets_catalog$ACTIVITE...Bq.=as.numeric(as.character(dechets_catalog$ACTIVITE...Bq.))

```

 on a crée une fonction pour donner la couleur correspondant aux communes en fonction de la classe potentiel :
Les communes à potentiel radon de catégorie 1 sont celles localisées sur les formations géologiques présentant les teneurs en uranium les plus faibles. 
Les communes à potentiel radon de catégorie 2 sont celles localisées sur des formations géologiques présentant des teneurs en uranium faibles mais sur lesquelles des facteurs géologiques particuliers peuvent faciliter le transfert du radon vers les bâtiments.
les communes à potentiel radon de catégorie 3 sont celles qui, sur au moins une partie de leur superficie, présentent des formations géologiques dont les teneurs en uranium sont estimées plus élevées comparativement aux autres formations.
```{r }
test<-match(departements$NOM_COM,radon_code$nom_comm)
couleurs<-radon_code$classe_potentiel[test]

getColor1 <- function(test) {
  sapply(test$classe_potentiel, function(classe_potentiel) {
    if(classe_potentiel== 1) {
      "green"
    } else if(classe_potentiel ==2) {
      "orange"
    } else {
      "red"
    } })
}

```

#Representation des cartes interactives:
#Repartition du potentiel radon par departement:
```{r }
 plot(departements,col=getColor1(catalogue_radon))
    legend ("right",legend=c("categorie1:plus faible","categorie2: faible","categorie3:plus élevé"),
            pch=22, pt.bg=c("red", "blue","green"),
bty="n", title="Classe potentiel Radon",title.adj=0.5,y.intersp=3, xjust=0.9,pt.cex=1.3,cex=0.9)
    
    title (main="Répartition du potentiel radon par commune ",
           cex.sub=0.7)

```
#Representation des déchets radioactifs en fonction des départements:
```{r }
dechets_catalog1 <- dechets_catalog %>% select(CODE_DEPT,NOM_DEPT ,CODE_REG,NOM_REG,Code_postal,Nom_commune,coordonnees_gps1,coordonnees_gps2)  %>%  unique()

#Calcul de la somme de l'ACTIVITE...Bq. par departement 
calcul_dept <- dechets_catalog %>% 
  group_by(CODE_DEPT) %>% 
  summarise(ACTIVITE...Bq. = sum(ACTIVITE...Bq.))

# fusionne les donnees "dechets_catalog1"  "calcul_dept" par CODE_DEPT .
dechets_catalog_dep <-merge(dechets_catalog1, calcul_dept , by ="CODE_DEPT")

#extaire les lignes en representants chaque departement par une seul commune
dechets_catalog_dep1 <- dechets_catalog_dep[c(1,5,6,7,15,16,17,21,22,23,29,31,32,33,
                                              34,37,39,43,44,45,46,51,54,57,65,69,79,
                                              90,108,113,120,122,128,139,143,145,152,
                                              158,165,166,167,168,172,181,184,186,188,
                                              189,191,203,206,210,214,218,220,221,228,
                                              234,240,243,246,247,249,261,266,276,277,
                                              281,282,283,288,293,294,299,305,315,322,
                                              330,339),]

#extraire les colonnes necessaires

dechets_catalog_dep1 <- dechets_catalog_dep1 %>% 
  select(CODE_DEPT,NOM_DEPT,ACTIVITE...Bq.,
         coordonnees_gps1,coordonnees_gps2)  %>%  unique()
leaflet(dechets_catalog_dep1) %>% addTiles() %>%
      addAwesomeMarkers(~coordonnees_gps2, ~coordonnees_gps1,
                        # clusterOptions = markerClusterOptions(),
                        icon=icons,  popup = ~as.character(NOM_DEPT),
                        label=~as.character(ACTIVITE...Bq.))

```
#Représentation des dechets radioactifs en fonction des communes en utlisant des cluster:
```{r }
 #Calcul de la somme de l'ACTIVITE...Bq. par commune
calcul_commune <- dechets_catalog %>% 
  group_by(Nom_commune) %>% 
  summarise(ACTIVITE...Bq. = sum(ACTIVITE...Bq.))

# fusionne les donnees
dechets_catalog_comun <-merge(dechets_catalog1, calcul_commune , by ="Nom_commune")

###premiere methode
leaflet(data =  dechets_catalog_comun) %>% addTiles() %>%
  addMarkers(~coordonnees_gps2, ~coordonnees_gps1,clusterOptions = markerClusterOptions(),
             popup = ~as.character(Nom_commune), 
             label = ~as.character(ACTIVITE...Bq.))




leaflet(dechets_catalog_comun) %>% addTiles() %>%
  addAwesomeMarkers(~coordonnees_gps2, ~coordonnees_gps1,
                    clusterOptions = markerClusterOptions(),
                    icon=icons,  popup = ~as.character(Nom_commune),
                    label=~as.character(ACTIVITE...Bq.))

```
Shiny Application :
Representation des dechets radioactif par catégorie et activité  de chaque etablissement dans les départements

```{r }
ui <- navbarPage("shinyApp",
                 tabPanel("présentation carte",
                          sidebarLayout(
                            sidebarPanel(
 selectInput("cat", label = "ACTIVITE...Bq",
                                         choices = c("MA-VL","TFA","FA-VL","FMA-VC","HA","AUTRES")
                             )
                            ),
                            mainPanel(
                              leafletOutput("lMap")
                              
                            )
                          )
                 ),
                 tabPanel("Summary",
                          verbatimTextOutput("tables")
                 ),
                 navbarMenu("More",
                            tabPanel("Table",
                                     DT::dataTableOutput("table")
                            )
                            
                            
                 )
)
server <- function(input, output, session) {
  output$lMap <- renderLeaflet({
    
    
    lo<- dechets_catalog %>% filter(CATEGORIE == input$cat)
    
      leaflet(lo) %>% addTiles() %>%
        addAwesomeMarkers(~coordonnees_gps2, ~coordonnees_gps1,
                          icon=icons,  popup = ~as.character(NOM_DEPT),
                          label=~as.character(ACTIVITE...Bq.))
      
    
      
    
  })
  
  output$summary <- renderPrint({
    summary()
  })
  
  output$table <- DT::renderDataTable({
    DT::datatable(dechets_catalog)
  })
}

shinyApp(ui, server)

```
Analyse spatial:
```{r }


eff_deprt <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/effectif.departement.csv'
eff_france <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/effectif.france.csv'

evenement <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/evenements.csv'
comm <- 'C:/Users/Mimia/Pictures/Documents/projet-ue4/metropole-densites-de-population-par-commune.csv'


# load data from csv
eff_deprt <- read.csv(eff_deprt, sep=";")
eff_france <-read.csv(eff_france, sep=";")
evenement <- read.csv(evenement, sep=";")
comm <-read.csv(comm, sep=";")




####2eme methode pour calculer l population dans chaque departement
calcul_popu <- dechets_catalog %>% 
  group_by(CODE_DEPT,NOM_DEPT) %>% 
  summarise(POPULATION = sum(POPULATION))




####nomrbre de malades dans chaque departement 
##♣evenement[,2:97] <- apply(evenement[,2:97], 2,
##  function(x) as.numeric(as.character(x)))
calcul_even <- apply(evenement[,2:97], 2, sum)
calcul_malade <-as.data.frame(calcul_even)
calcul_malade <- t(calcul_malade )
calcul_popu<-cbind(calcul_popu,observed=c(16,12,8,7,6,12,7,7,4,10,4,20,17,6,11,
                                         9,6,18,14,0,14,30,14,5,25,0,13,28,25,
                                         22,26,4,8,21,12,7,28,26,12,5,10,4,8,
                                         15,21,36,16,3,80,23,20,16,13,5,4,49,
                                         12,52,11,18,19,6,27,27,12,9,7,14,9,19,5,19,5,12,18,36,31,25,17,
                                         11,18,19,6,27,27,12,9,7,14,9
                                         ))
##calcul de la population expecteé
calcul_popu<-cbind(calcul_popu,expected=calcul_popu$POPULATION*sum(calcul_popu$observed)/sum(calcul_popu$POPULATION))

localisation <- dechets_catalog_dep1 %>% 
  select(CODE_DEPT,coordonnees_gps1,coordonnees_gps2,ACTIVITE...Bq.)  %>%  unique()

calcul_popu <-merge(calcul_popu, localisation , by ="CODE_DEPT")


	#Compute Stones statistic around a location
#for (x in 1:60){region<-calcul_popu[x,2]
region<-which(row.names(calcul_popu$NOM_DEPT)=="AIN")
stone.stat(calcul_popu, region=70, lambda=1)
test <- stone.test(observed~offset(log(expected)), calcul_popu, model="poisson", R=99,
           region=region, lambda=1)
#}

```

les données utilisées dans les calculs de la correlation   sont extraites du fichier "evenement.csv" qui contient le nombre de cas dans chaque departement ,fusionné à la fois avec le fichier "code-postal-code-insee-2015.csv" qui contient les données de localisation géographique et la population dans chaque département et le fichier "dechets-declares-au-31-12-2015.csv" pour calculer  l'activité en Bq  dans chaque departement ,a fin de construire le fichier "calcul_popu" dont les données :
le nom et le code du département,Population,
Observed :nombre de cas  malade dans chaque departement 
Expected : standariser les cas observés 
 Coordonnees_gps X et Y de chaque departement 

Les phénomènes de corrélation spatiale sont présents lorsque les relevés sont proches spatialement les uns des autres. La corrélation spatiale peut conduire à sous-estimer la variance de la variable observée, et donc à surestimer la précision obtenue.

En présence de corrélation spatiale, la loi binomiale conduit à sous-estimer la variance de la moyenne. Cependant, il est possible de modéliser la corrélation par une expression corrigée de la variance, c'est-à-dire avec un coefficient qui traduit la sur-dispersion. La loi bêta-binomiale et d'autres modèles quant à eux permettent d'obtenir une expression de la variance proche de celle que l'on pourrait obtenir avec la loi binomiale. Ils impliquent l'utilisation d'un paramètre d'ajustement qui lorsqu'il est positif indique la sur-dispersion et lorsqu'il est nul indique que tous les individus observés sont indépendants.
On a utilisé le teste de STONE qui genere la valeur du teste statique et le nombre de regions  pour lesquelles le risque accumulé maximumde maladie X est atteint

Type of boots.: parametric 
	Model used when sampling: Poisson 
	Number of simulations: 99 
	Statistic:  -Inf 
	p-value :  0.01 
	les resultat ci-dessous du test stone la taille du cluster et 1 pour le departement ("AIN") qui est significant

